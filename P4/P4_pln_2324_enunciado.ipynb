{"cells":[{"cell_type":"markdown","metadata":{"id":"OUBRwgEu3yu1"},"source":["# Práctica 4: Procesamiento del Lenguaje Natural\n","\n","__Fecha de entrega: 14 de mayo de 2024__\n","\n","El objetivo de esta práctica es aplicar los conceptos teóricos vistos en clase en el módulo de PLN.\n","\n","Lo más importante en esta práctica no es el código Python, sino el análisis de los datos y modelos que construyas y las explicaciones razonadas de cada una de las decisiones que tomes. __No se valorarán trozos de código o gráficas sin ningún tipo de contexto o explicación__.\n","\n","Finalmente, recuerda establecer el parámetro `random_state` en todas las funciones que tomen decisiones aleatorias para que los resultados sean reproducibles (los resultados no varíen entre ejecuciones)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V3YxCTUW3yu9"},"outputs":[],"source":["# Ziteng Huang y Lubin Ye\n","\n","RANDOM_STATE = 1234"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import nltk\n","import re\n","import numpy as np\n","import csv\n","import pandas as pd\n","\n","from sklearn.model_selection import train_test_split\n","from collections import Counter"]},{"cell_type":"markdown","metadata":{"id":"yeVD_g2D3yvC"},"source":["# 1) Carga del conjunto de datos\n","\n","El fichero `spam.csv` contiene mensajes SMS etiquetados como spam or ham (legítimo).\n","\n","Muestra un ejemplo de cada clase.\n","\n","Haz un estudio del conjunto de datos. ¿qué palabras aparecen más veces?, ¿tendría sentido normalizar de alguna manera el corpus?\n","\n","Crea una partición de los datos dejando el 60% para entrenamiento, 20% para validación y el 20% restante para test. Comprueba que la distribución de los ejemplos en las particiones es similar. "]},{"cell_type":"markdown","metadata":{},"source":["RESPUESTA:\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Cargar dataset -> encoding=\"latin1\"\n","\n","def load_data():\n","    corpus = []\n","    labels = []\n","    with open('spam.csv', 'r', encoding=\"latin1\") as f:\n","        reader = csv.reader(f)\n","        reader.__next__()\n","        for row in reader:\n","            corpus.append(row[1])\n","            labels.append(row[0])\n","\n","    corpus_df = pd.DataFrame({'Document': corpus, \n","                        'Category': labels})\n","\n","    return corpus, labels, corpus_df\n","\n","\n","corpus, labels, corpus_df = load_data()\n","\n","corpus_df\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Contar palabras más frecuentes -> palabras sin significado\n","\n","def contar_palabras(corpus):\n","    lista_palabras = []\n","    for text in corpus:\n","        lista_palabras.extend(text.split(\" \"))\n","\n","    counter = Counter(lista_palabras)\n","    palabras_mas_comunes = counter.most_common()\n","\n","    # Palabras más comunes\n","    print(\"Palabras más comunes:\")\n","    for palabra, frecuencia in palabras_mas_comunes:\n","        print(f\"{palabra}: {frecuencia}\")\n","\n","contar_palabras(corpus)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["wpt = nltk.WordPunctTokenizer()\n","nltk.download('stopwords')\n","stop_words = nltk.corpus.stopwords.words('english')\n","\n","def normalize_document(doc):\n","    # lower case and remove special characters\\whitespaces\n","    doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I|re.A)\n","    doc = doc.lower()\n","    doc = doc.strip()\n","    # tokenize document\n","    tokens = wpt.tokenize(doc)\n","    # filter stopwords out of document\n","    filtered_tokens = [token for token in tokens if token not in stop_words]\n","    # re-create document from filtered tokens\n","    doc = ' '.join(filtered_tokens)\n","    return doc\n","\n","normalize_corpus = np.vectorize(normalize_document)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Borrar palabras sin signifcado (stop words)\n","\n","norm_corpus = normalize_corpus(corpus)\n","norm_corpus"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Volvemos a contar ahora las palabras más comunes después de normalizar\n","\n","contar_palabras(norm_corpus)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Split data en training, validacion y test\n","\n","def split_data(corpus, labels):\n","    \n","    corpus_train, corpus_val_test, labels_train, labels_val_test = train_test_split(corpus, labels, test_size=0.4, random_state=RANDOM_STATE)\n","    corpus_val, corpus_test, labels_val, labels_test = train_test_split(corpus_val_test, labels_val_test, test_size=0.5, random_state=RANDOM_STATE)\n","\n","    corpus_df_train = pd.DataFrame({'Document': corpus_train, \n","                           'Category': labels_train})\n","    \n","    corpus_df_val = pd.DataFrame({'Document': corpus_val,\n","                                    'Category': labels_val})\n","                                    \n","    corpus_df_test = pd.DataFrame({'Document': corpus_test,\n","                                    'Category': labels_test})\n","\n","    return corpus_df_train, corpus_df_val, corpus_df_test\n","\n","\n","corpus_df_train, corpus_df_val, corpus_df_test = split_data(norm_corpus, labels)\n","corpus_df_train"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","def plot_class_distribution(corpus_df, title):\n","    plt.figure(figsize=(6,6))\n","    corpus_df['Category'].value_counts().plot(kind='bar', color=['skyblue', 'orange'])\n","    plt.title(title)\n","    plt.xlabel('Category')\n","    plt.ylabel('Count')\n","    plt.show()\n","\n","plot_class_distribution(corpus_df_train, \"Training dataset\")\n","plot_class_distribution(corpus_df_val, \"Validation dataset\")\n","plot_class_distribution(corpus_df_test, \"Test dataset\")\n"]},{"cell_type":"markdown","metadata":{"id":"r4rXv3xX3yvG"},"source":["# 2) Representación como bolsa de palabras\n","\n","Elige justificadamente una representación de bolsa de palabras y aplícala.\n","Muestra un ejemplo antes y después de aplicar la representación. Explica los cambios."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","def get_tfidf_features(corpus):\n","    tv = TfidfVectorizer()\n","    tv_matrix = tv.fit_transform(corpus)\n","    tv_matrix = tv_matrix.toarray()\n","\n","    vocab = tv.get_feature_names_out()\n","    return pd.DataFrame(np.round(tv_matrix, 2), columns=vocab)\n","\n","# Ejemplo de frecuencia de las palabras de los primeros 5 documentos\n","print(get_tfidf_features(norm_corpus[:5]))\n","\n","# Ejemplo de frecuencia de todos los documentos\n","print(get_tfidf_features(norm_corpus))"]},{"cell_type":"markdown","metadata":{},"source":["# 3) Aplica 3 algoritmos de aprendizaje automático para resolver la tarea\n","\n","Justifica porqué los has elegido.\n","Ajusta los modelos respecto a un hiperparámetro que consideres oportuno. Justifica tu elección.\n","Explica los resultados obtenidos."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Árbol de decisión \n","\n","from sklearn import tree\n","import numpy as np\n","\n","vectorizer = TfidfVectorizer()\n","train_preprocessed = vectorizer.fit_transform(corpus_df_train[\"Document\"]).toarray()\n","test_preprocessed = vectorizer.transform(corpus_df_test[\"Document\"]).toarray()\n","\n","# Creamos el clasificador con los valores por defecto\n","tree_classifier = tree.DecisionTreeClassifier()\n","tree_classifier.fit(train_preprocessed, corpus_df_train[\"Category\"])\n","\n","tree_train_predictions = tree_classifier.predict(train_preprocessed)\n","tree_test_predictions = tree_classifier.predict(test_preprocessed)\n","\n","print(\"Árbol, porcentaje de aciertos en entrenamiento:\", np.mean(tree_train_predictions == corpus_df_train[\"Category\"]))\n","print(\"Árbol, porcentaje de aciertos en test:\", np.mean(tree_test_predictions == corpus_df_test[\"Category\"]))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# k Vecinos Más Cercanos (k-NN)\n","\n","from sklearn import neighbors\n","\n","knn_classifier = neighbors.KNeighborsClassifier()\n","knn_classifier.fit(train_preprocessed, corpus_df_train[\"Category\"])\n","\n","knn_train_predictions = knn_classifier.predict(train_preprocessed)\n","knn_test_predictions = knn_classifier.predict(test_preprocessed)\n","\n","print(\"k-NN, porcentaje de aciertos en entrenamiento:\", np.mean(knn_train_predictions == corpus_df_train[\"Category\"]))\n","print(\"k-NN, porcentaje de aciertos en test:\", np.mean(knn_test_predictions == corpus_df_test[\"Category\"]))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Naive Bayes\n","\n","from sklearn.naive_bayes import MultinomialNB\n","\n","mnb_classifier = MultinomialNB()\n","\n","mnb_classifier.fit(train_preprocessed, corpus_df_train[\"Category\"])\n","\n","mnb_train_predictions = mnb_classifier.predict(train_preprocessed)\n","mnb_test_predictions = mnb_classifier.predict(test_preprocessed)\n","\n","print(\"Multinomial Naive Bayes, porcentaje de aciertos en entrenamiento:\", np.mean(mnb_train_predictions == corpus_df_train[\"Category\"]))\n","print(\"Multinomial Naive Bayes, porcentaje de aciertos en test:\", np.mean(mnb_test_predictions == corpus_df_test[\"Category\"]))"]},{"cell_type":"markdown","metadata":{},"source":["# 4) Construye redes neuronales con Keras con distintas maneras de usar word embeddings\n","\n","Justifica tus decisiones y explica los resultados obtenidos."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# 5) Aplica los modelos construidos a los datos de test y compáralos.\n","\n","Calcula las métricas de recall, precisión y f1.\n","Discute cual es el mejor modelo y cual es peor y porqué."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
